{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>semicol</th>\n",
       "      <th>paren</th>\n",
       "      <th>bracket</th>\n",
       "      <th>bang</th>\n",
       "      <th>dollar</th>\n",
       "      <th>pound</th>\n",
       "      <th>cap_avg</th>\n",
       "      <th>cap_long</th>\n",
       "      <th>cap_total</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.666</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.510</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.718</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.426</td>\n",
       "      <td>72</td>\n",
       "      <td>819</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.428</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   make  address   all   3d   our  over  remove  internet  order  mail  ...  \\\n",
       "0  0.00     0.00  0.29  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "1  0.46     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "2  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "3  0.33     0.44  0.37  0.0  0.14  0.11    0.00      0.07   0.97  1.16  ...   \n",
       "4  0.00     2.08  0.00  0.0  3.12  0.00    1.04      0.00   0.00  0.00  ...   \n",
       "\n",
       "   semicol  paren  bracket   bang  dollar  pound  cap_avg  cap_long  \\\n",
       "0    0.000  0.178      0.0  0.044   0.000   0.00    1.666        10   \n",
       "1    0.000  0.125      0.0  0.000   0.000   0.00    1.510        10   \n",
       "2    0.000  0.000      0.0  0.000   0.000   0.00    1.718        11   \n",
       "3    0.006  0.159      0.0  0.069   0.221   0.11    3.426        72   \n",
       "4    0.000  0.000      0.0  0.263   0.000   0.00    1.428         4   \n",
       "\n",
       "   cap_total  Class  \n",
       "0        180    ham  \n",
       "1         74    ham  \n",
       "2         55    ham  \n",
       "3        819   spam  \n",
       "4         20   spam  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store CSV of given dataset into DataFrame.\n",
    "\n",
    "csv_file = \"spam.csv\"\n",
    "# spam_df = pd.read_csv(csv_file, index_col=0)\n",
    "spam_df = pd.read_csv(csv_file)\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows are :  4601\n",
      "total columns are :  58\n"
     ]
    }
   ],
   "source": [
    "#Checking number of rows & columns.\n",
    "\n",
    "total_rows=len(spam_df.axes[0])\n",
    "total_cols=len(spam_df.axes[1])\n",
    "print('total rows are : ', total_rows)\n",
    "print('total columns are : ', total_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null values in dataframe.\n",
    "\n",
    "spam_df.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^The result is \"False\" after running the above line of code, which means there are no null values in the given dataset. Hence, we will move forward with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows assigned to \"Class Spam\" = 1813\n",
      "Total number of rows assigned to \"Class Ham\" = 2788\n"
     ]
    }
   ],
   "source": [
    "#Dataframe for class 'spam'\n",
    "class_spam = spam_df.loc[spam_df['Class'] == 'spam']\n",
    "\n",
    "#\n",
    "total_spam_rows=len(class_spam.axes[0])\n",
    "print('Total number of rows assigned to \"Class Spam\" =', total_spam_rows)\n",
    "\n",
    "#------\n",
    "\n",
    "#Dataframe for class 'ham'\n",
    "class_ham = spam_df.loc[spam_df['Class'] == 'ham']\n",
    "\n",
    "#\n",
    "total_ham_rows=len(class_ham.axes[0])\n",
    "print('Total number of rows assigned to \"Class Ham\" =', total_ham_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Task: Train the classifiers using the first 1000 instances and use the remaining 3601 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new dataframes = (1000, 58) , (3601, 58)\n"
     ]
    }
   ],
   "source": [
    "# splitting dataframe by row index\n",
    "train_df = spam_df.iloc[:1000,:]\n",
    "test_df = spam_df.iloc[1000:,:]\n",
    "print(\"Shape of new dataframes = {} , {}\".format(train_df.shape, test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet',\n",
       "       'order', 'mail', 'receive', 'will', 'people', 'report', 'addresses',\n",
       "       'free', 'business', 'email', 'you', 'credit', 'your', 'font', '0',\n",
       "       'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857',\n",
       "       'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct',\n",
       "       'cs', 'meeting', 'original', 'project', 're', 'edu', 'table',\n",
       "       'conference', 'semicol', 'paren', 'bracket', 'bang', 'dollar', 'pound',\n",
       "       'cap_avg', 'cap_long', 'cap_total', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking names of columns.\n",
    "spam_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data model for Training\n",
    "x_train = train_df[['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet',\n",
    "                   'order', 'mail', 'receive', 'will', 'people', 'report', 'addresses',\n",
    "                   'free', 'business', 'email', 'you', 'credit', 'your', 'font', '0',\n",
    "                   'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857',\n",
    "                   'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct',\n",
    "                   'cs', 'meeting', 'original', 'project', 're', 'edu', 'table',\n",
    "                   'conference', 'semicol', 'paren', 'bracket', 'bang', 'dollar', 'pound',\n",
    "                   'cap_avg', 'cap_long', 'cap_total']]\n",
    "\n",
    "y_train = train_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data model for Testing\n",
    "x_test = test_df[['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet',\n",
    "                   'order', 'mail', 'receive', 'will', 'people', 'report', 'addresses',\n",
    "                   'free', 'business', 'email', 'you', 'credit', 'your', 'font', '0',\n",
    "                   'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857',\n",
    "                   'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct',\n",
    "                   'cs', 'meeting', 'original', 'project', 're', 'edu', 'table',\n",
    "                   'conference', 'semicol', 'paren', 'bracket', 'bang', 'dollar', 'pound',\n",
    "                   'cap_avg', 'cap_long', 'cap_total']]\n",
    "\n",
    "y_test = test_df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fuse three classifiers: (1) k-Nearest Neighbor, (2) Random Forest, (3) Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Fused Classifier  ~\n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9255762288253263 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.96      0.94      2182\n",
      "        spam       0.94      0.87      0.90      1419\n",
      "\n",
      "    accuracy                           0.93      3601\n",
      "   macro avg       0.93      0.92      0.92      3601\n",
      "weighted avg       0.93      0.93      0.93      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2099   83]\n",
      " [ 185 1234]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fusion of three classifiers: (1) k-Nearest Neighbor, (2) Random Forest, (3) Logistic Regression\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#------------------------------------------------------\n",
    "\n",
    "model_KN = KNeighborsClassifier()\n",
    "model_KN = model_KN.fit(x_train, y_train)\n",
    "score_KN = model_KN.score(x_train, y_train)\n",
    "\n",
    "model_RF = RandomForestClassifier()\n",
    "model_RF = model_RF.fit(x_train, y_train)\n",
    "score_RF = model_RF.score(x_train, y_train)\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "model_LR = model_LR.fit(x_train, y_train)\n",
    "score_LR = model_LR.score(x_train, y_train)\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('kn', model_KN))\n",
    "    models.append(('rf', model_RF))\n",
    "    models.append(('lr', model_LR))\n",
    "    return models\n",
    "\n",
    "\n",
    "fused_clf = VotingClassifier(estimators=get_models(), voting='hard')     #If ‘hard’, uses predicted class labels for majority rule voting.\n",
    "fused_clf = fused_clf.fit(x_train,y_train)\n",
    "\n",
    "# Metrics - Fused Classifier \n",
    "fused_predict = fused_clf.predict(x_test)\n",
    "fused_accuracy = accuracy_score(y_test, fused_predict)\n",
    "fused_class_repo = classification_report(y_test, fused_predict)\n",
    "fused_cm = confusion_matrix(y_test, fused_predict)\n",
    "\n",
    "print(\"~ Fused Classifier  ~\\n\")\n",
    "print(\"Classification Accuracy: \\n\", fused_accuracy, \"\\n\")\n",
    "print(\"Classification Report: \\n\",  \"(Here, 'recall' is per class classification accuracy.)\\n\", fused_class_repo) \n",
    "print(\"Confusion Matrix: \\n\", fused_cm, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost Ensemble with Decision Tree as the base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ AdaBoost Ensemble ~\n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9197445154123854 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.94      0.93      2182\n",
      "        spam       0.90      0.89      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.92      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2049  133]\n",
      " [ 156 1263]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Ensemble with Decision Tree as the base learner\n",
    "#-----------------------------------------------------------\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#-----------------------------------------------\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier()     #If 'None', then the base estimator is 'DecisionTreeClassifier' initialized with max_depth=1.\n",
    "adaboost_clf = adaboost_clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Metrics - AdaBoost Ensemble\n",
    "adaboost_predict = adaboost_clf.predict(x_test)\n",
    "adaboost_accuracy = accuracy_score(y_test, adaboost_predict)\n",
    "adaboost_class_repo = classification_report(y_test, adaboost_predict)\n",
    "adaboost_cm = confusion_matrix(y_test, adaboost_predict)\n",
    "\n",
    "print(\"~ AdaBoost Ensemble ~\\n\")\n",
    "print(\"Classification Accuracy: \\n\", adaboost_accuracy, \"\\n\")\n",
    "print(\"Classification Report: \\n\",  \"(Here, 'recall' is per class classification accuracy.)\\n\", adaboost_class_repo) \n",
    "print(\"Confusion Matrix: \\n\", adaboost_cm, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Task: train-test splits: 50%-50%, 60%-40%, 70%-30%, and 80%-20%  for both, the fused classifier and the AdaBoost Ensemble with Decision Tree as the base learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== SPLIT 0.5 ==========================\n",
      "\n",
      "~~~~~~~~~~~~~ Fused Classifier for split 0.5 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.5 = (2300, 58) , (2301, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9247431269091919 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.96      0.94      2182\n",
      "        spam       0.94      0.87      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.93      0.91      0.92      3601\n",
      "weighted avg       0.93      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2098   84]\n",
      " [ 187 1232]] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~ Adaboost Classifier for split 0.5 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.5 = (2300, 58) , (2301, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9197445154123854 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.94      0.93      2182\n",
      "        spam       0.90      0.89      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.92      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2049  133]\n",
      " [ 156 1263]] \n",
      "\n",
      "\n",
      "========================== SPLIT 0.6 ==========================\n",
      "\n",
      "~~~~~~~~~~~~~ Fused Classifier for split 0.6 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.6 = (2760, 58) , (1841, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9266870313801722 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.96      0.94      2182\n",
      "        spam       0.94      0.87      0.90      1419\n",
      "\n",
      "    accuracy                           0.93      3601\n",
      "   macro avg       0.93      0.92      0.92      3601\n",
      "weighted avg       0.93      0.93      0.93      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2104   78]\n",
      " [ 186 1233]] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~ Adaboost Classifier for split 0.6 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.6 = (2760, 58) , (1841, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9197445154123854 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.94      0.93      2182\n",
      "        spam       0.90      0.89      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.92      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2049  133]\n",
      " [ 156 1263]] \n",
      "\n",
      "\n",
      "========================== SPLIT 0.7 ==========================\n",
      "\n",
      "~~~~~~~~~~~~~ Fused Classifier for split 0.7 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.7 = (3220, 58) , (1381, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.924187725631769 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.96      0.94      2182\n",
      "        spam       0.93      0.87      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.93      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2096   86]\n",
      " [ 187 1232]] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~ Adaboost Classifier for split 0.7 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.7 = (3220, 58) , (1381, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9197445154123854 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.94      0.93      2182\n",
      "        spam       0.90      0.89      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.92      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2049  133]\n",
      " [ 156 1263]] \n",
      "\n",
      "\n",
      "========================== SPLIT 0.8 ==========================\n",
      "\n",
      "~~~~~~~~~~~~~ Fused Classifier for split 0.8 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.8 = (3680, 58) , (921, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9264093307414607 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.96      0.94      2182\n",
      "        spam       0.94      0.87      0.90      1419\n",
      "\n",
      "    accuracy                           0.93      3601\n",
      "   macro avg       0.93      0.92      0.92      3601\n",
      "weighted avg       0.93      0.93      0.93      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2097   85]\n",
      " [ 180 1239]] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~ Adaboost Classifier for split 0.8 ~~~~~~~~~~~~~\n",
      "\n",
      "Shape of dataframes for split 0.8 = (3680, 58) , (921, 58) \n",
      "\n",
      "Classification Accuracy: \n",
      " 0.9197445154123854 \n",
      "\n",
      "Classification Report: \n",
      " (Here, 'recall' is per class classification accuracy.)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.94      0.93      2182\n",
      "        spam       0.90      0.89      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.92      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2049  133]\n",
      " [ 156 1263]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#-----------------------------------------------------\n",
    "\n",
    "split_list = [0.5, 0.6, 0.7, 0.8]\n",
    "new_shape = []\n",
    "\n",
    "fused_clf = VotingClassifier(estimators=get_models(), voting='hard')     #If ‘hard’, uses predicted class labels for majority rule voting.\n",
    "adaboost_clf = AdaBoostClassifier()     #If 'None', then the base estimator is 'DecisionTreeClassifier' initialized with max_depth=1.\n",
    "\n",
    "\n",
    "for i in split_list:\n",
    "    train_df, test_df = train_test_split(spam_df, train_size=i)\n",
    "    \n",
    "    print(\"========================== SPLIT\", i, \"==========================\\n\")\n",
    "    #~~~~~~~~~~~~~Fused~~~~~~~~~~~~~\n",
    "    print(\"~~~~~~~~~~~~~ Fused Classifier for split\", i, \"~~~~~~~~~~~~~\\n\")\n",
    "    new_shape.append(print(\"Shape of dataframes for split\", i, \"= {} , {} \\n\".format(train_df.shape, test_df.shape)))\n",
    "    \n",
    "    fused_clf = fused_clf.fit(x_train,y_train)\n",
    "    \n",
    "     #Metrics - Fused Classifier \n",
    "    fused_predict = fused_clf.predict(x_test)\n",
    "    fused_accuracy = accuracy_score(y_test, fused_predict)\n",
    "    fused_class_repo = classification_report(y_test, fused_predict)\n",
    "    fused_cm = confusion_matrix(y_test, fused_predict)\n",
    "    \n",
    "    print(\"Classification Accuracy: \\n\", fused_accuracy, \"\\n\")\n",
    "    print(\"Classification Report: \\n\",  \"(Here, 'recall' is per class classification accuracy.)\\n\", fused_class_repo) \n",
    "    print(\"Confusion Matrix: \\n\", fused_cm, \"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    #~~~~~~~~~~~~~Adaboost~~~~~~~~~~~~~\n",
    "    print(\"~~~~~~~~~~~~~ Adaboost Classifier for split\", i, \"~~~~~~~~~~~~~\\n\")\n",
    "    new_shape.append(print(\"Shape of dataframes for split\", i, \"= {} , {} \\n\".format(train_df.shape, test_df.shape)))\n",
    "    \n",
    "    adaboost_clf = adaboost_clf.fit(x_train, y_train)\n",
    "\n",
    "    # Metrics - AdaBoost Ensemble\n",
    "    adaboost_predict = adaboost_clf.predict(x_test)\n",
    "    adaboost_accuracy = accuracy_score(y_test, adaboost_predict)\n",
    "    adaboost_class_repo = classification_report(y_test, adaboost_predict)\n",
    "    adaboost_cm = confusion_matrix(y_test, adaboost_predict)\n",
    "\n",
    "    print(\"Classification Accuracy: \\n\", adaboost_accuracy, \"\\n\")\n",
    "    print(\"Classification Report: \\n\",  \"(Here, 'recall' is per class classification accuracy.)\\n\", adaboost_class_repo) \n",
    "    print(\"Confusion Matrix: \\n\", adaboost_cm, \"\\n\\n\")\n",
    "    \n",
    "    i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
